\PassOptionsToPackage{unicode=true}{hyperref} % options for packages loaded elsewhere
\PassOptionsToPackage{hyphens}{url}
\documentclass[11pt,dvipsnames,ignorenonframetext,aspectratio=169]{beamer}
\IfFileExists{pgfpages.sty}{\usepackage{pgfpages}}{}
\setbeamertemplate{caption}[numbered]
\setbeamertemplate{caption label separator}{: }
\setbeamercolor{caption name}{fg=normal text.fg}
\beamertemplatenavigationsymbolsempty
\usepackage{lmodern}
\usepackage{amssymb,amsmath}
\usepackage{ifxetex,ifluatex}
\usepackage{fixltx2e} % provides \textsubscript
\ifnum 0\ifxetex 1\fi\ifluatex 1\fi=0 % if pdftex
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
\else % if luatex or xelatex
  \ifxetex
    \usepackage{mathspec}
  \else
    \usepackage{fontspec}
\fi
\defaultfontfeatures{Ligatures=TeX,Scale=MatchLowercase}







\fi

  \usetheme[]{monash}

  \usecolortheme{monashwhite}


% A default size of 24 is set in beamerthememonash.sty


  \useinnertheme{rounded}

  \useoutertheme{smoothtree}

% use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
% use microtype if available
\IfFileExists{microtype.sty}{%
  \usepackage{microtype}
  \UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}


\newif\ifbibliography


\hypersetup{
      pdftitle={LOD score},
            colorlinks=true,
    linkcolor=red,
    citecolor=Blue,
    urlcolor=lightgrayd,
    breaklinks=true}
%\urlstyle{same}  % Use monospace font for urls







% Prevent slide breaks in the middle of a paragraph:
\widowpenalties 1 10000
\raggedbottom

  \AtBeginPart{
    \let\insertpartnumber\relax
    \let\partname\relax
    \frame{\partpage}
  }
  \AtBeginSection{
    \ifbibliography
    \else
      \let\insertsectionnumber\relax
      \let\sectionname\relax
      \frame{\sectionpage}
    \fi
  }
  \AtBeginSubsection{
    \let\insertsubsectionnumber\relax
    \let\subsectionname\relax
    \frame{\subsectionpage}
  }



\setlength{\parindent}{0pt}
\setlength{\parskip}{6pt plus 2pt minus 1pt}
\setlength{\emergencystretch}{3em}  % prevent overfull lines
\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}

  \setcounter{secnumdepth}{0}


%% Monash overrides
\AtBeginSection[]{
   \frame<beamer>{
   \frametitle{Outline}\vspace*{0.2cm}
   
   \tableofcontents[currentsection,hideallsubsections]
  }}

% Redefine shaded environment if it exists (to ensure text is black)
\ifcsname Shaded\endcsname
  \definecolor{shadecolor}{RGB}{225,225,225}
  \renewenvironment{Shaded}{\color{black}\begin{snugshade}\color{black}}{\end{snugshade}}
\fi
%%

  \usepackage{setspace}
  \usepackage{wasysym}
  % \usepackage{footnote} % don't use this this breaks all
  \usepackage{fontenc}
  \usepackage{fontawesome}
  \usepackage{booktabs,siunitx}
  \usepackage{longtable}
  \usepackage{array}
  \usepackage{multirow}
  \usepackage{wrapfig}
  \usepackage{float}
  \usepackage{colortbl}
  \usepackage{pdflscape}
  \usepackage{tabu}
  \usepackage{threeparttable}
  \usepackage{threeparttablex}
  \usepackage[normalem]{ulem}
  \usepackage{makecell}
  \usepackage{xcolor}
  \usepackage{tikz} % required for image opacity change
  \usepackage[absolute,overlay]{textpos} % for text formatting
  \usepackage[skip=0.333\baselineskip]{caption}
  \usepackage{chemfig}
  \usepackage[skip=0.333\baselineskip]{caption}
  % \newcommand*{\AlignChar}[1]{\makebox[1ex][c]{\ensuremath{\scriptstyle#1}}}%
  
  % this font option is amenable for beamer
  \setbeamerfont{caption}{size=\tiny}
  \singlespacing
  \definecolor{lightgrayd}{gray}{0.95}
  \definecolor{skyblued}{rgb}{0.65, 0.6, 0.94}
  \definecolor{oranged}{RGB}{245, 145, 200}

  \title[]{LOD score}


  \author[
        Deependra Dhakal\\
Gokuleshwor Agriculture and Animal Science College\\
Tribhuwan University\\
\textit{ddhakal.rookie@gmail.com}\\
\url{https://rookie.rbind.io}
    ]{Deependra Dhakal\\
Gokuleshwor Agriculture and Animal Science College\\
Tribhuwan University\\
\textit{ddhakal.rookie@gmail.com}\\
\url{https://rookie.rbind.io}}


\date[
      Academic year 2019-2020
  ]{
      Academic year 2019-2020
        }

\begin{document}

% Hide progress bar and footline on titlepage
  \begin{frame}[plain]
  \titlepage
  \end{frame}


   \frame<beamer>{
   \frametitle{Outline}\vspace*{0.2cm}
   
   \tableofcontents[hideallsubsections]
  }

\hypertarget{lod-score}{%
\section{LOD score}\label{lod-score}}

\begin{frame}{}
\protect\hypertarget{section}{}

\begin{itemize}
\tightlist
\item
  Genetic markers located on the same chromosome tend to remain together
  during sexual reproduction (linkage groups).
\item
  That is, they do not exhibit independent assortment. Consequently,
  there are as many linkage groups as there are homologous pairs of
  chromosomes.
\item
  Manual linkage analysis is feasible if only a few markers are being
  studied.
\item
  Modern linkage map construction is a computerized operation, feasible
  through mapping software packages. - These computer software packages
  use the coded information from the segregating population to determine
  recombination frequencies.
\item
  The basic calculation is a ratio (odds ratio) of linkage versus no
  linkage, expressed as the log of the ratio (logarithm of odds or LOD).
\end{itemize}

\end{frame}

\begin{frame}{}
\protect\hypertarget{section-1}{}

\begin{itemize}
\tightlist
\item
  The LOD score compares the likelihood of obtaining the test data if
  the two loci are indeed linked, to the likelihood of observing the
  same data purely by chance.
\item
  A \textbf{LOD value} or score measures the likelihood of linkage
  between two markers, a score of more than three usually being the
  cut-off minimum for mapping.
\item
  Positive LOD scores favour the presence of linkage, whereas negative
  LOD scores indicate that linkage is less likely.
\item
  A LOD of three indicates a 1000:1 odds in favor of genetic linkage
  (linkage between the two markers is a thousand times more likely than
  no linkage).
\item
  The researcher may vary the stringency of mapping by, for example,
  lowering the LOD score to detect a greater level of linkage.
\end{itemize}

\end{frame}

\begin{frame}{}
\protect\hypertarget{section-2}{}

Linear regression models are defined by the equation

\[
Y = \beta_0 + \beta_1x_1 + \beta_2x_2 + \beta_qx_q + \epsilon; \epsilon \sim N(0, \sigma^2)
\]

which calculates the response \(Y\) directly. Logisitc regression is
defined in a similar manner,

Consider a model with two predictors, \({\displaystyle x_{1}}\) and
\({\displaystyle x_{2}}\), and one binary (Bernoulli) response variable
\({\displaystyle Y}\), which we denote \({\displaystyle p=P(Y=1)}\). We
assume a linear relationship between the predictor variables, and the
log-odds of the event that \({\displaystyle Y=1}\).

This linear relationship can be written in the following mathematical
form (where \(\ell\) is the log-odds, \(b\) is the base of the
logarithm, and \({\displaystyle \beta _{i}}\) are parameters of the
model):

\[
{\displaystyle \ell =\log _{b}\left({\frac {p(\mathbf{x})}{1-p(\mathbf{x})}}\right)=\beta _{0}+\beta _{1}x_{1}+...+\beta _{p-1}x_{p-1}}
\]

\end{frame}

\begin{frame}{}
\protect\hypertarget{section-3}{}

\begin{itemize}
\tightlist
\item
  In binary context, the odds are probability for a `positive' event
  (\(Y = 1\)) divided by the probability of `negative' event
  (\(Y = 0\)).
\end{itemize}

\[
\frac{p(\mathbf{x})}{1-p(\mathbf{x})} = \frac{P[Y = 1 | \mathbf{X} = \mathbf{x}]}{P[Y = 0 | \mathbf{X} = \mathbf{x}]}
\]

\begin{itemize}
\tightlist
\item
  The logistic regression equation guarantees that a value between 0 and
  1 is calculated. This is evident the when the inverse logit
  transformation is applied, which results in a ``direct'' probability
  prediction.
\end{itemize}

\[
p(\mathbf{x_i}) = P[Y = 1 | \mathbf{X} = \mathbf{x}] = \frac{\exp^{\beta_0 + \beta_1x_1 + ... + \beta_{p-1}x_{i(p-1)}}}{1 + \exp^{\beta_0 + \beta_1x_1 + ... + \beta_{p-1}x_{i(p-1)}}}
\]

\begin{itemize}
\tightlist
\item
  Note that this is prediction of ``probability'', not a numerical
  value. This probability value must be translated to a categorical
  prediction.
\end{itemize}

\end{frame}

\begin{frame}[fragile]{}
\protect\hypertarget{section-4}{}

We can recover the odds by exponentiating the log-odds:

\[
{\displaystyle {\frac {p}{1-p}}=b^{\beta _{0}+\beta _{1}x_{1}+\beta _{2}x_{2}}}.
\]

By simple algebraic manipulation, the probability that
\({\displaystyle Y=1}\) is

\[
{\displaystyle p={\frac {b^{\beta _{0}+\beta _{1}x_{1}+\beta _{2}x_{2}}}{b^{\beta _{0}+\beta _{1}x_{1}+\beta _{2}x_{2}}+1}}={\frac {1}{1+b^{-(\beta _{0}+\beta _{1}x_{1}+\beta _{2}x_{2})}}}}
\]

The above formula shows that once \({\displaystyle \beta _{i}}\) are
fixed, we can easily compute either the log-odds that
\({\displaystyle Y=1}\) for a given observation, or the probability that
\({\displaystyle Y=1}\) for a given observation. The main use-case of a
logistic model is to be given an observation
\({\displaystyle (x_{1},x_{2})}\), and estimate the probability
\({\displaystyle p}\) that \({\displaystyle Y=1}\). In most
applications, the base \({\displaystyle b}\) of the logarithm is usually
taken to be \texttt{e}.

\end{frame}

\begin{frame}{Example: Inerpreting logarithm of odds}
\protect\hypertarget{example-inerpreting-logarithm-of-odds}{}

We consider an example with \({\displaystyle b=10}\), and coefficients
\({\displaystyle \beta _{0}=-3}\) \({\displaystyle \beta _{1}=1}\)
\({\displaystyle \beta _{2}=2}\). To be concrete, the model is

\[
{\displaystyle \log _{10}{\frac {p}{1-p}}=\ell =-3+x_{1}+2x_{2}}
\]

where \({\displaystyle p}\) is the probability of the event that
\({\displaystyle Y=1}\).

\end{frame}

\begin{frame}{}
\protect\hypertarget{section-5}{}

\begin{itemize}
\tightlist
\item
  This can be interpreted as follows:

  \begin{itemize}
  \tightlist
  \item
    \({\displaystyle \beta _{0}=-3}\) is the y-intercept. It is the
    log-odds of the event that \({\displaystyle Y=1}\), when the
    predictors \({\displaystyle x_{1}=x_{2}=0}\). By exponentiating, we
    can see that when \({\displaystyle x_{1}=x_{2}=0}\) the odds of the
    event that \({\displaystyle Y=1}\) are 1-to-1000, or
    \({\displaystyle 10^{-3}}\) . Similarly, the probability of the
    event that \({\displaystyle Y=1}\) when
    \({\displaystyle x_{1}=x_{2}=0}\) can be computed as
    \({\displaystyle 1/(1000+1)=1/1001}\).
  \item
    \({\displaystyle \beta _{1}=1}\) means that increasing
    \({\displaystyle x_{1}}\) by 1 increases the log-odds by
    \({\displaystyle 1}\). So if \({\displaystyle x_{1}}\) increases by
    1, the odds that \({\displaystyle Y=1}\) increase by a factor of
    \({\displaystyle 10^{1}}\).
  \item
    \({\displaystyle \beta _{2}=2}\) means that increasing
    \({\displaystyle x_{2}}\) by 1 increases the log-odds by
    \({\displaystyle 2}\). So if \({\displaystyle x_{2}}\) increases by
    1, the odds that \({\displaystyle Y=1}\) increase by a factor of
    \({\displaystyle 10^{2}.}\) Note how the effect of
    \({\displaystyle x_{2}}\) on the log-odds is twice as great as the
    effect of \({\displaystyle x_{1}}\), but the effect on the odds is
    10 times greater.
  \end{itemize}
\item
  In order to estimate the parameters \({\displaystyle \beta _{i}}\)
  from data, one must do logistic regression.
\end{itemize}

\end{frame}

\begin{frame}{Example: Probability of passing an exam versus hours of
study}
\protect\hypertarget{example-probability-of-passing-an-exam-versus-hours-of-study}{}

\begin{itemize}
\item
  A group of 20 students spends between 0 and 6 hours studying for an
  exam. How does the number of hours spent studying affect the
  probability of the student passing the exam?
\item
  The reason for using logistic regression for this problem is that the
  values of the dependent variable, pass and fail, while represented by
  ``1'' and ``0'', are not cardinal numbers. If the problem was changed
  so that pass/fail was replaced with the grade 0--100 (cardinal
  numbers), then simple regression analysis could be used.
\end{itemize}

\end{frame}

\begin{frame}{}
\protect\hypertarget{section-6}{}

\begin{itemize}
\tightlist
\item
  The table shows the number of hours each student spent studying, and
  whether they passed (1) or failed (0).
\end{itemize}

\begin{table}[H]
\centering\begingroup\fontsize{6}{8}\selectfont

\begin{tabular}{rrrr}
\toprule
Hours & Pass & Hours1 & Pass1\\
\midrule
\rowcolor{gray!6}  0.50 & 0 & 2.8 & 1\\
0.75 & 0 & 3.0 & 0\\
\rowcolor{gray!6}  1.00 & 0 & 3.2 & 1\\
1.25 & 0 & 3.5 & 0\\
\rowcolor{gray!6}  1.50 & 0 & 4.0 & 1\\
\addlinespace
1.75 & 0 & 4.2 & 1\\
\rowcolor{gray!6}  1.75 & 1 & 4.5 & 1\\
2.00 & 0 & 4.8 & 1\\
\rowcolor{gray!6}  2.25 & 1 & 5.0 & 1\\
2.50 & 0 & 5.5 & 1\\
\bottomrule
\end{tabular}
\endgroup{}
\end{table}

\end{frame}

\begin{frame}{}
\protect\hypertarget{section-7}{}

\small

\begin{columns}[T,onlytextwidth]
  \column{.6\linewidth}

The graph shows the probability of passing the exam versus the number of hours studying, with the logistic regression curve fitted to the data.


\begin{center}\includegraphics[width=0.8\linewidth]{02-manipulation_of_dna_lod_score_files/figure-beamer/log-reg-curve-1} \end{center}

  \column{.4\linewidth}

The logistic regression gives the following output:

\begin{table}[H]
\centering
\resizebox{\linewidth}{!}{
\begin{tabular}{lrrrr}
\toprule
term & estimate & std.error & statistic & p.value\\
\midrule
(Intercept) & -4.1 & 1.76 & -2.3 & 0.02\\
Hours & 1.5 & 0.63 & 2.4 & 0.02\\
\bottomrule
\end{tabular}}
\end{table}

\end{columns}

\end{frame}

\begin{frame}{}
\protect\hypertarget{section-8}{}

The output indicates that hours studying is significantly associated
with the probability of passing the exam ( \({\displaystyle p=0.0167}\),
Wald test). The output also provides the coefficients for
\({\displaystyle {\text{Intercept}}=-4.0777}\) and
\({\displaystyle {\text{Hours}}=1.5046}\). The coefficient for Hours
values indicate change in the log odds of passing the exam due to one
unit change in Hours (i.e. \(\beta_1\) coefficient). These coefficients
are entered in the logistic regression equation to estimate the odds
(probability) of passing the exam:

\[
{\displaystyle {\begin{aligned}{\text{Log-odds of passing exam}}&=1.5046\cdot {\text{Hours}}-4.0777=1.5046\cdot ({\text{Hours}}-2.71)\\{\text{Odds of passing exam}}&=\exp \left(1.5046\cdot {\text{Hours}}-4.0777\right)=\exp \left(1.5046\cdot ({\text{Hours}}-2.71)\right)\\{\text{Probability of passing exam}}&={\frac {1}{1+\exp \left(-\left(1.5046\cdot {\text{Hours}}-4.0777\right)\right)}}\end{aligned}}}
\]

\end{frame}

\begin{frame}{}
\protect\hypertarget{section-9}{}

\begin{itemize}
\item
  One additional hour of study is estimated to increase log-odds of
  passing by 1.5, so multiplying odds of passing by
  \({\displaystyle \exp(1.5046)\approx 4.5.}\) The form with the
  x-intercept (2.71) shows that this estimates even odds (log-odds 0,
  odds 1, probability 1/2) for a student who studies 2.71 hours.
\item
  For example, for a student who studies 2 hours, entering the value
  \({\displaystyle {\text{Hours}}=2}\) in the equation gives the
  estimated probability of passing the exam of 0.26:
\end{itemize}

\[{\displaystyle {\text{Probability of passing exam}}={\frac {1}{1+\exp \left(-\left(1.5046\cdot 2-4.0777\right)\right)}}=0.26}\]

\begin{itemize}
\tightlist
\item
  Similarly, for a student who studies 4 hours, the estimated
  probability of passing the exam is 0.87:
\end{itemize}

\[{\displaystyle {\text{Probability of passing exam}}={\frac {1}{1+\exp \left(-\left(1.5046\cdot 4-4.0777\right)\right)}}=0.87}\]

\end{frame}

\begin{frame}{}
\protect\hypertarget{section-10}{}

This table shows the probability of passing the exam for several values
of hours studying.

\begin{table}[H]
\centering\begingroup\fontsize{6}{8}\selectfont

\begin{tabular}{rrrl}
\toprule
Hours & log\_odds & p\_value & odds\\
\midrule
\rowcolor{gray!6}  0.0 & -4.08 & 0.02 & 0.02\\
1.0 & -2.57 & 0.07 & 0.08\\
\rowcolor{gray!6}  2.0 & -1.07 & 0.26 & 0.34\\
3.0 & 0.44 & 0.61 & 1.55\\
\rowcolor{gray!6}  4.0 & 1.94 & 0.87 & 6.96\\
\addlinespace
5.0 & 3.45 & 0.97 & 31.36\\
\rowcolor{gray!6}  6.0 & 4.95 & 0.99 & 141.20\\
7.0 & 6.45 & 1.00 & 635.75\\
\rowcolor{gray!6}  8.0 & 7.96 & 1.00 & 2862.50\\
9.0 & 9.46 & 1.00 & 12888.56\\
\addlinespace
\rowcolor{gray!6}  10.0 & 10.97 & 1.00 & 58031.48\\
2.7 & 0.00 & 0.50 & 1.00\\
\bottomrule
\end{tabular}
\endgroup{}
\end{table}

\end{frame}

\begin{frame}{}
\protect\hypertarget{section-11}{}

The output from the logistic regression analysis gives a p-value of
\({\displaystyle p=0.0167}\), which is based on the Wald z-score. Rather
than the Wald method, the recommended method to calculate the p-value
for logistic regression is the likelihood-ratio test (LRT), which for
this data gives \({\displaystyle p=0.0006}\).

\end{frame}

\begin{frame}[fragile]{Example: Proportions of female children at
various ages during adolescence who have reached menarche}
\protect\hypertarget{example-proportions-of-female-children-at-various-ages-during-adolescence-who-have-reached-menarche}{}

The coefficient returned by a logistic regression in r is a logit, or
the log of the odds. To convert logits to odds ratio, you can
exponentiate it, as you've done above. To convert logits to
probabilities, you can use the function
\texttt{exp(logit)/(1+exp(logit))}. However, there are some things to
note about this procedure.

First, lets generate some reproducible data to illustrate. We fit a
generalized linear model to menarche dataset with response variable as
function of Age. The coefficients displayed are for logits, just as in
your example. The \texttt{predict()} gives the predicted value in terms
of logits.

\end{frame}

\begin{frame}{}
\protect\hypertarget{section-12}{}

\begin{table}[H]
\centering\begingroup\fontsize{6}{8}\selectfont

\begin{tabular}{lrrrr}
\toprule
term & estimate & std.error & statistic & p.value\\
\midrule
\rowcolor{gray!6}  (Intercept) & -21.2 & 0.77 & -28 & 0\\
Age & 1.6 & 0.06 & 28 & 0\\
\bottomrule
\end{tabular}
\endgroup{}
\end{table}

If we plot these data and this model, we see the sigmoidal function that
is characteristic of a logistic model fit to binomial data.

\begin{center}\includegraphics[width=0.45\linewidth]{02-manipulation_of_dna_lod_score_files/figure-beamer/binomial-probability-plot-1} \end{center}

\end{frame}

\begin{frame}{}
\protect\hypertarget{section-13}{}

Note that the change in probabilities is not constant - the curve rises
slowly at first, then more quickly in the middle, then levels out at the
end. The difference in probabilities between 10 and 12 is far less than
the difference in probabilities between 12 and 14. This means that it's
impossible to summarise the relationship of age and probabilities with
one number without transforming probabilities.

To answer the specific questions: How do you interpret odds ratios?

The odds ratio for the value of the intercept is the odds of a
``success'' (in your data, this is the odds of taking the product) when
x = 0 (i.e.~zero thoughts). The odds ratio for your coefficient is the
increase in odds above this value of the intercept when you add one
whole x value (i.e.~x=1; one thought). Using the menarche data:

\begin{table}[H]
\centering\begingroup\fontsize{6}{8}\selectfont

\begin{tabular}{lr}
\toprule
names & x\\
\midrule
\rowcolor{gray!6}  (Intercept) & 0.0\\
Age & 5.1\\
\bottomrule
\end{tabular}
\endgroup{}
\end{table}

\end{frame}

\begin{frame}[fragile]{}
\protect\hypertarget{section-14}{}

We could interpret this as the odds of menarche occurring at age = 0 is
.00000000006. Or, basically impossible. Exponentiating the age
coefficient tells us the expected increase in the odds of menarche for
each unit of age. In this case, it's just over a quintupling. An odds
ratio of 1 indicates no change, whereas an odds ratio of 2 indicates a
doubling, etc.

Your odds ratio of 2.07 implies that a 1 unit increase in `Thoughts'
increases the odds of taking the product by a factor of 2.07.

How do you convert odds ratios of thoughts to an estimated probability
of decision?

You need to do this for selected values of thoughts, because, as you can
see in the plot above, the change is not constant across the range of x
values. If you want the probability of some value for thoughts, get the
answer as follows:

\texttt{exp(intercept\ +\ coef*THOUGHT\_Value)/(1+(exp(intercept+coef*THOUGHT\_Value)))}

\end{frame}

\begin{frame}{}
\protect\hypertarget{section-15}{}

For another example refer to: Mapping QTL in populations with known
pedigrees in Griffiths et al. (2015) (pp 742).

\end{frame}

\hypertarget{bibliography}{%
\section{Bibliography}\label{bibliography}}

\begin{frame}{References}
\protect\hypertarget{references}{}

\hypertarget{refs}{}
\leavevmode\hypertarget{ref-griffiths2015introduction}{}%
Griffiths, Anthony JF, Susan R Wessler, Sean B Carroll, Doebley John,
and others. 2015. \emph{An Introduction to Genetic Analysis}. Macmillan.

\end{frame}




\end{document}
